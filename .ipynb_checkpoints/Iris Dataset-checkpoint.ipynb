{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris Dataset Notebook\n",
    "\n",
    "## Contents\n",
    "\n",
    "## About the Iris Dataset\n",
    "The [Iris flower data set](https://en.wikipedia.org/wiki/Iris_flower_data_set) is a dataset containing 50 samples of each of three species of Iris flowers; Setosa, Versicolor and Virginica. Along with the species, the dataset contains measurements on the sepal length, sepal width, petal length, and petal width for each sample. \n",
    "\n",
    "Created by the statistician Ronald Fisher in 1936 as an example of linear discriminant analysis, which is a method used to find a linear combination of features that characterises or separates two or more classes of objects. So the purpose of the dataset is to use measurements on the morphology of the samples and use that to distinguish the species from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hughballs\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd                    # for interacting with data sets\n",
    "import matplotlib.pyplot as pl         # plotting package\n",
    "import seaborn as sb                   # for styling plots\n",
    "\n",
    "import keras as kr                     # for building neural networks\n",
    "import sklearn.preprocessing as pre    # For encoding categorical variables.\n",
    "import sklearn.model_selection as mod  # For splitting into training and test sets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ds = pd.read_csv(\"https://raw.githubusercontent.com/uiuc-cse/data-fa14/gh-pages/data/iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
