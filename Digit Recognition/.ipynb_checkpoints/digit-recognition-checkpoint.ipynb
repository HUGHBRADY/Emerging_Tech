{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Recognition\n",
    "digitrec.py is a Python script that takes an image file containing a handwritten digit and identifies the digit using a supervised learning algorithm. This will be done using the MNIST dataset to train and test the neural network. This script uses [keras](https://github.com/keras-team/keras), a high level neural network API. \n",
    "\n",
    "### Digit Dataset\n",
    "First things first, we need to open and read the MNIST dataset. This has already been covered in the [MNIST dataset notebook](https://github.com/HUGHBRADY/Emerging_Tech/blob/master/MNIST%20Dataset/mnist-dataset.ipynb) in this repository. \n",
    "\n",
    "### Imports & MNIST set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hughballs\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras as kr\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "import gzip\n",
    "\n",
    "# Open and read all of the MNIST files\n",
    "with gzip.open('data/t10k-images-idx3-ubyte.gz', 'rb') as f:  \n",
    "    raw_test_img = f.read()\n",
    "with gzip.open('data/t10k-labels-idx1-ubyte.gz', 'rb') as f:  \n",
    "    raw_test_lbl = f.read()\n",
    "with gzip.open('data/train-images-idx3-ubyte.gz', 'rb') as f:  \n",
    "    raw_train_img = f.read()\n",
    "with gzip.open('data/train-labels-idx1-ubyte.gz', 'rb') as f:  \n",
    "    raw_train_lbl = f.read()\n",
    "\n",
    "# Next we'll trimodelthe excess bytes at the start and convert the bytes to integers\n",
    "test_img = np.frombuffer(raw_test_img, dtype = np.uint8, offset = 16) / 255\n",
    "test_lbl = np.frombuffer(raw_test_lbl, dtype = np.uint8, offset = 8)\n",
    "train_img = np.frombuffer(raw_train_img, dtype = np.uint8, offset = 16) / 255\n",
    "train_lbl = np.frombuffer(raw_train_lbl, dtype = np.uint8, offset = 8)\n",
    "\n",
    "# Finally we reshape the image arrays\n",
    "test_img  =  test_img.reshape(10000, 784)\n",
    "train_img = train_img.reshape(60000, 784)\n",
    "\n",
    "# Convert class vectors to binary class matrices \n",
    "train_lbl = kr.utils.to_categorical(train_lbl, 10)\n",
    "test_lbl = kr.utils.to_categorical(test_lbl, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras \n",
    "We also need to set up our neural network. Keras' core data structure is a model, which is a way to organize layers. The simpliest of these models is the Sequential model so it's the perfect one to start learning with. \n",
    "\n",
    "### Building the Model\n",
    "The Sequential model is a linear stack of layers. The most important layers are the first and last, or input and output layers. The input layer defines the shape of the input. \n",
    "There is a dense connection between the neurons meaning that every neuron in every layer is connected to every neuron in the neighbouring layers.\n",
    "The output layer has ten neurons that correspond to the possible answers (0 - 9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1000)              785000    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 1,796,010\n",
      "Trainable params: 1,796,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create our keras model\n",
    "model = kr.models.Sequential()\n",
    "\n",
    "# Layers to add to our sequential model. The first layer defines the input shape\n",
    "# Dropout randomly selects nodes to drop, resulting in a network capable of better generalization\n",
    "model.add(Dense(1000, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))                                                 \n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once these layers are added we must compile the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines the loss function, optimizer and metrics and is needed for training\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model\n",
    "Once the model has been built and the images have been read in, we have to train the model to recognize the images. The training set of 60000 images are used and passed to the networks first layer of 784 neurons. The training images are sent as input and the training labels are attached as the expected output. Epochs refer to the amount of times the input will be processed, which I've set to 20. Finally the batch size in this case refers the amount of images that will be sent into the neural network at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 22s 362us/step - loss: 0.2157 - acc: 0.9346 - val_loss: 0.0930 - val_acc: 0.9707\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 21s 349us/step - loss: 0.0987 - acc: 0.9714 - val_loss: 0.0863 - val_acc: 0.9758\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 20s 336us/step - loss: 0.0752 - acc: 0.9791 - val_loss: 0.0922 - val_acc: 0.9776\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 21s 342us/step - loss: 0.0682 - acc: 0.9826 - val_loss: 0.0830 - val_acc: 0.9819\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 20s 336us/step - loss: 0.0585 - acc: 0.9845 - val_loss: 0.0858 - val_acc: 0.9815\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 20s 334us/step - loss: 0.0553 - acc: 0.9859 - val_loss: 0.0906 - val_acc: 0.9811\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 21s 348us/step - loss: 0.0513 - acc: 0.9875 - val_loss: 0.1073 - val_acc: 0.9799\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 20s 339us/step - loss: 0.0472 - acc: 0.9890 - val_loss: 0.1096 - val_acc: 0.9823\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 20s 339us/step - loss: 0.0445 - acc: 0.9895 - val_loss: 0.1071 - val_acc: 0.9829\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 21s 357us/step - loss: 0.0397 - acc: 0.9911 - val_loss: 0.1450 - val_acc: 0.9810\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 22s 367us/step - loss: 0.0430 - acc: 0.9906 - val_loss: 0.1087 - val_acc: 0.9827\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 24s 394us/step - loss: 0.0398 - acc: 0.9915 - val_loss: 0.1241 - val_acc: 0.9797\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 23s 377us/step - loss: 0.0385 - acc: 0.9918 - val_loss: 0.1231 - val_acc: 0.9826\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 23s 376us/step - loss: 0.0369 - acc: 0.9925 - val_loss: 0.1293 - val_acc: 0.9811\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 21s 358us/step - loss: 0.0362 - acc: 0.9923 - val_loss: 0.1363 - val_acc: 0.9826\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 22s 359us/step - loss: 0.0324 - acc: 0.9939 - val_loss: 0.1324 - val_acc: 0.9829\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 22s 363us/step - loss: 0.0333 - acc: 0.9937 - val_loss: 0.1473 - val_acc: 0.9829\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 22s 359us/step - loss: 0.0352 - acc: 0.9934 - val_loss: 0.1281 - val_acc: 0.9828\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 22s 361us/step - loss: 0.0342 - acc: 0.9937 - val_loss: 0.1509 - val_acc: 0.9809\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 21s 356us/step - loss: 0.0391 - acc: 0.9933 - val_loss: 0.1476 - val_acc: 0.9807\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2199e898e80>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_img, train_lbl, batch_size=100, epochs=20, validation_data=(test_img, test_lbl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output\n",
    "Return the results of the loses and the accuracy of the mnist neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.14759161900484996\n",
      "Test accuracy: 0.9807\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_img, test_lbl, verbose=0)\n",
    "\n",
    "# Finally, print the loss and the accuracy\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
